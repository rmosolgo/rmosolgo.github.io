<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ruby | Robert Mosolgo]]></title>
  <link href="http://rmosolgo.github.io/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://rmosolgo.github.io/"/>
  <updated>2020-07-27T16:05:47-04:00</updated>
  <id>http://rmosolgo.github.io/</id>
  <author>
    <name><![CDATA[Robert Mosolgo]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Finding implicit returns with Rubocop]]></title>
    <link href="http://rmosolgo.github.io/blog/2019/11/14/finding-implicit-returns-with-rubocop/"/>
    <updated>2019-11-14T09:57:00-05:00</updated>
    <id>http://rmosolgo.github.io/blog/2019/11/14/finding-implicit-returns-with-rubocop</id>
    <content type="html"><![CDATA[<p>Some notes on a refactor implemented with a Cop.</p>

<!-- more -->


<p>I&rsquo;ve developed a real affection for Rubocop over the last couple of years. (Sorry to my old coworkers and friends at Planning Center, who put up with my complaining about it back then!) What I&rsquo;ve come to appreciate is:</p>

<ul>
<li><strong>No fights about style.</strong> If it passes the linter, it&rsquo;s ok to ship.</li>
<li><strong>Enforcing usage coventions.</strong> For example, we have a cop to make sure that some risky methods aren&rsquo;t used in the codebase.</li>
<li><strong>Upgrading old code.</strong> For example, we realized we were sometimes using <code>Promise.all(...) do</code> instead of <code>Promise.all(...).then do</code>. The old code didn&rsquo;t work at all. We added a Cop with an <code>autocorrect</code> implementation, so we could upgrade any mistakes automatically!</li>
</ul>


<h2>The Refactor: Returning Promises</h2>

<p>We have some GraphQL/GraphQL-Batch code for making authorization checks. It looks like this:</p>

<pre><code class="ruby">class Types::Repository
  # This is GraphQL-Ruby's authorization API
  def self.authorized?(repository, ctx)
    # Load some data which is required for the check:
    batch_load(repository, :owner).then do |owner|
      # Call the authorization code:
      Authorization.can_see?(ctx[:viewer], repository, owner)
    end
  end
end
</code></pre>

<p>The <code>authorized?</code> check returns a <code>Promise</code> (for GraphQL-Batch), and inside that promise, <code>.can_see?</code> returns <code>true</code> or <code>false</code> (synchronously).</p>

<p>However, to improve data access, we wanted to implement a new authorization code path:</p>

<pre><code class="ruby"># Returns Promise&lt;true|false&gt;
Authorization.async_can_see?(viewer, repo, owner)
</code></pre>

<p>This new code path would improve the database access under the hood to use our batch loading system.</p>

<p>After implementing the codepath, how could we update the ~1000 call sites to use the new method?</p>

<h2>The Problem: Boolean Logic</h2>

<p>The easiest solution would be find-and-replace, but that doesn&rsquo;t quite work because of boolean logic with Promises. Some of our authorization checks combined two checks like this:</p>

<pre><code class="ruby"># Require both checks to pass:
Authorization.can_see?(...) &amp;&amp; Authorization.can_see?(...)
</code></pre>

<p>If we updated that to <code>async_can_see?</code>, that code would break. It would break because <code>async_can_see?</code> <em>always</em> returns a <code>Promise</code>, which is truthy. That is:</p>

<pre><code class="ruby">promise_1 &amp;&amp; promise_2
</code></pre>

<p>That code <em>always</em> returns true, even if one of the promises <em>would</em> resolve to <code>false</code>. (The Ruby <code>Promise</code> object is truthy, and we don&rsquo;t have access to the returned value until we call <code>promise.sync</code>.)</p>

<p>So, we have to figure out <em>which code paths</em> can be automatically upgraded.</p>

<h2>The Solution, In Theory</h2>

<p>Roughly, the answer is:</p>

<blockquote><p>If an authorization <em>returns the value</em> of <code>.can_see?</code>, then we can replace that call with <code>.async_can_see?</code>.</p></blockquote>

<p>This is true because GraphQL-Ruby is happy to receive <code>Promise&lt;true|false&gt;</code> &ndash; it will use its batching system to resolve it as late as possible.</p>

<p>So, how can we find cases when <code>.can_see?</code> is used as a return value? There are roughly two possibilities:</p>

<ul>
<li>explicit <code>return</code>s, which we don&rsquo;t use often</li>
<li>implicit returns, which are the last expressions of any branches in the method body.</li>
</ul>


<p>This post covers that <em>second case</em>, implicit returns. We want to find implicit returns which are <em>just</em> calls to <code>.can_see?</code>, and automatically upgrade them. (Some calls will be left over, we&rsquo;ll upgrade those by hand.)</p>

<p>We assume that any code which is <em>more complicated</em> than <em>just</em> a call to <code>.can_see?</code> can&rsquo;t be migrated, because it might depend on the synchronous return of <code>true|false</code>. We&rsquo;ll revisit those by hand.</p>

<h2>The Implementation: A Cop</h2>

<p>I knew I wanted two things:</p>

<ul>
<li>For new code, require <code>async_can_see?</code> whenever possible</li>
<li>For existing code, upgrade to <code>async_can_see?</code> whenever it&rsquo;s possible</li>
</ul>


<p>Rubocop will do both of these things:</p>

<ul>
<li>A linting rule will fail the build if invalid code is added to the project, addressing the first goal</li>
<li>A well-implemented <code>def autocorrect</code> will fix existing violations, addressing the second goal</li>
</ul>


<p>But it all depends on implementing the check well: can I find implicit returns? Fortunately, I only need to find them <em>well enough</em>: it doesn&rsquo;t have to find <em>every possible</em> Ruby implicit return; it only has to find the ones actually used in the codebase!</p>

<p>By an approach of trial and error, here&rsquo;s what I ended up with:</p>

<pre><code class="ruby"># frozen_string_literal: true
class AsyncCanSeeWhenPossible &lt; Rubocop::Cop
  MSG = &lt;&lt;-ERR
When `.can_see?` is the last call inside an authorization method, use
`.async_can_see?` instead so that the underlying data access can be batched.
ERR

  # If the given node is a call to `:can_see?`, it's yielded
  def_node_matcher :can_see_call, "$(send s(:const, {nil (cbase)}, :Authorization) :can_see? ...)"

  # Look for nested promises -- treat the body of a nested promise just like the method body.
  # (That is, the implicit return of the block is like the implicit return of the method)
  def_node_matcher :then_block, "(block (send _ :then) _ $({begin send block if case} ...))"

  # Check for `def self.authorized?` and call the cop on that method
  def on_defs(node)
    _self, method_name, *_args, method_body = *node
    if method_name == :authorized?
      check_implicit_return(method_body)
    end
  end

  # Replace `.can_see?` with `.async_can_see?`
  def autocorrect(node)
    lambda do |corrector|
      _receiver, method_name, *rest = *node
      corrector.replace(node.location.selector, "async_can_see?")
    end
  end

  private

  # Continue traversing `node` until you get to the last expression.
  # If that expression is a call to `.can_see?`, then add an offense.
  def check_implicit_return(node)
    case node.type
    when :begin
      # This node is a series of expressions.
      # The last one is the implicit return.
      *_prev_exps, last_expression = *node
      check_implicit_return(last_expression)
    when :block
      # It's a method call that receives a block.
      # If it's a then-block, check its body for implicit returns.
      then_block(node) do |block_body|
        check_implicit_return(block_body)
      end
    when :if
      # Check each branch of an `if ...` expression, because
      # each branch may be an implicit return
      # (elsif is part of the `else_exp`)
      _check, if_exp, else_exp = *node
      check_implicit_return(if_exp)
      # This can be null if there is no else expression
      if else_exp
        check_implicit_return(else_exp)
      end
    when :case
      # Check each branch of the case statement, since each one
      # could be an implicit return.
      _subject, *when_exps, else_exp = *node
      when_exps.each do |when_exp|
        *_when_conditions, condition_body = *when_exp
        check_implicit_return(condition_body)
      end
      # There may or may not be an `else` branch.
      if else_exp
        check_implicit_return(else_exp)
      end
    when :send
      # This is a method call -- if it's a plain call to `.can_see?`, flag it.
      can_see_call(node) do |bad_call|
        add_offense(bad_call, location: :selector)
      end
    else
      # We've reached an implicit return which is not:
      #
      # - An expression containing other implicit returns
      # - An expression calling `.can_see?`, which we know to upgrade
      #
      # So, ignore this implicit return.
    end
  end
end
</code></pre>

<p>With this cop, <code>rubocop -a</code> will upgrade the easy cases in existing code, then I&rsquo;ll track down the harder ones by hand.</p>

<p>I think the implementation could be improved by:</p>

<ul>
<li><strong>Also checking explicit <code>return</code>s.</strong> It wasn&rsquo;t important for me because there weren&rsquo;t any in this code base. <code>next</code> Could probably be treated the same way, since it exists <code>then</code> blocks.</li>
<li><strong>Flagging <em>any</em> use of <code>.can_see?</code>,</strong> not only the easy ones. I expect that some usages are inevitable, but better to require a <code>rubocop:disable</code> in that case to mark that it&rsquo;s not best-practice.</li>
</ul>


<p>(Full disclosure: we haven&rsquo;t shipped this refactor yet. But I enjoyed the work on it so far, so I thought I&rsquo;d write up what I learned!)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Breaking out of a yield with return]]></title>
    <link href="http://rmosolgo.github.io/blog/2019/09/02/breaking-out-of-a-yield-with-return/"/>
    <updated>2019-09-02T11:28:00-04:00</updated>
    <id>http://rmosolgo.github.io/blog/2019/09/02/breaking-out-of-a-yield-with-return</id>
    <content type="html"><![CDATA[<p>Did you know that calling <code>return</code> in one Ruby method could affect the flow of another method? I discovered it today while hunting a <a href="https://github.com/rmosolgo/graphql-ruby/commit/400bb71bc">GraphQL-Ruby bugfix</a>. You can get more reliable behavior with <code>ensure</code>, if it&rsquo;s appropriate.</p>

<!-- more -->


<h3>Instrumentating a block</h3>

<p>Let&rsquo;s imagine a simple instrumentation system, where method wraps a block of code and tags it with a name:</p>

<pre><code class="ruby">def instrument_event(event_name)
  puts "begin    #{event_name}"
  result = yield
  puts "end      #{event_name}"
  result
end
</code></pre>

<p>You could use this to instrument a method call, for example:</p>

<pre><code class="ruby">def do_stuff_with_instrumentation
  instrument_event("do-stuff") do
    do_stuff
  end
end

do_stuff_with_instrumentation
# begin    do-stuff
# end      do-stuff
</code></pre>

<p>It prints the <code>begin</code> message, then the <code>end</code> message.</p>

<h3>Returning early</h3>

<p>But what if you return early from the block? For example:</p>

<pre><code class="ruby"># @param return_early [Boolean] if true, return before actually doing the stuff
def do_stuff_with_instrumentation(return_early:)
  instrument_event("do-stuff") do
    if return_early
      # Return from this method ... but also return from the `do ... end` instrumentation block
      return
    else
      do_stuff
    end
  end
end
</code></pre>

<p>If you instrument it <em>without</em> returning from inside the block, it logs normally:</p>

<pre><code class="ruby">do_stuff_with_instrumentation(return_early: false)
# begin    do-stuff
# end      do-stuff
</code></pre>

<p>But, if you return early, you only get <em>half</em> the log:</p>

<pre><code class="ruby">do_stuff_with_instrumentation(return_early: true)
# begin    do-stuff
</code></pre>

<p>Where&rsquo;s the <code>end</code> message?</p>

<h3>It Jumped!</h3>

<p>Apparently, the <code>return</code> inside the inner method (<code>#do_stuff_with_instrumentation</code>) broke out of its own method <em>and</em> out of <code>#instrument_event</code>. I don&rsquo;t know why it works like that.</p>

<h3>With Ensure</h3>

<p>If you refactor the instrumentation to use <code>ensure</code>, it won&rsquo;t have this issue. Here&rsquo;s the refactor:</p>

<pre><code class="ruby">def instrument_event(event_name)
  puts "begin    #{event_name}"
  yield
ensure
  puts "end      #{event_name}"
end
</code></pre>

<p>Then, it prints normally:</p>

<pre><code class="ruby">do_stuff_with_instrumentation(return_early: true)
# begin    do-stuff
# end      do-stuff
</code></pre>

<p>Of course, this also changes the behavior of the method when errors happen. The <code>ensure</code> code will be called <em>even if</em> <code>yield</code> raises an error. So, it might not always be the right choice. (I bet you could use <code>$!</code> to detect a currently-raised error, though.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A New Runtime in GraphQL-Ruby 1.9]]></title>
    <link href="http://rmosolgo.github.io/blog/2019/01/29/a-new-runtime-in-graphql-ruby-1-dot-9/"/>
    <updated>2019-01-29T07:22:00-05:00</updated>
    <id>http://rmosolgo.github.io/blog/2019/01/29/a-new-runtime-in-graphql-ruby-1-dot-9</id>
    <content type="html"><![CDATA[<p>GraphQL-Ruby 1.9.0 introduces a new runtime called <code>GraphQL::Execution::Interpreter</code>. It offers better performance and some new features.</p>

<!-- more -->


<p>In <a href="https://github.com/rmosolgo/graphql-ruby/issues/861#issuecomment-458533219">isolated benchmarks</a>, the new runtime is about 50% faster. We saw about a 10% speedup in GitHub when we migrated.</p>

<p>You can opt in by adding to your schema:</p>

<pre><code class="ruby">class MySchema &lt; GraphQL::Schema
  # To use the new runtime
  use GraphQL::Execution::Interpreter
  # To skip preprocessing (you can use the interpreter without adding this)
  use GraphQL::Analysis::AST
end
</code></pre>

<p>But why rewrite?</p>

<h2>Problem 1: per-field context objects</h2>

<p>Previously, each field evaluated by GraphQL-Ruby got its own instance of <code>GraphQL::Query::Context::FieldResolutionContext</code>. This was introduced so that fields using <code>graphql-batch</code>-style Promises could reliably access context values (like <code>ctx.path</code>) <em>after</em> returning from the resolver (ie, when the promise was synced.)</p>

<p>The problem was, the bigger the response, the more <code>ctx</code> objects would be created &ndash; and most of the time (for example, plain scalar fields), they were never <em>used</em> by application code. So, we allocated, initialized, then GCed these objects for nothing!</p>

<p>In fact, it wasn&rsquo;t for <em>nothing</em>. As time passed, I started using those context objects inside execution code. For example, null propagation was implemented by climbing <em>up</em> the tree of context objects. So you couldn&rsquo;t just <em>stop</em> creating them &ndash; the runtime depended on them.</p>

<h3>Solution: one mutable context</h3>

<p>To remove this performance issue, I went <em>back</em> to creating a single <code>Query::Context</code> object and passing it to resolvers. If you&rsquo;re using the new class-based API, you might have noticed that <code>self.context</code> is a <code>Query::Context</code>, not a <code>Query::Context::FieldResolutionContext</code>. I did it this way to pave the way for removing this bottleneck.</p>

<p>But what about access to runtime information?</p>

<h3>Solution: explicit requests for runtime info</h3>

<p>For fields that <em>want</em> runtime info (like <code>path</code> or <code>ast_node</code>), they can opt into it with <code>extras: [...]</code>, for example:</p>

<pre><code class="ruby">field :items, ..., extras: [:path]
</code></pre>

<p>By adding that configuration, the requested value will be injected into the resolver:</p>

<pre><code class="ruby">def items(path:)
  # ...
end
</code></pre>

<p><code>path</code> will be a frozen Array describing the current point in the GraphQL response.</p>

<h3>Solution: reimplementing the runtime</h3>

<p>Finally, since <code>FieldResolutionContext</code>s aren&rsquo;t necessary for user code, we can rewrite execution to <em>not</em> create or use them anymore. Under the hood, <code>GraphQL::Execution::Interpreter</code> doesn&rsquo;t create those <code>ctx</code> objects. Instead, null propagation is implemented manually and all necessary values are passed from method to method.</p>

<h2>Problem 2: inefficient preprocessing</h2>

<p>Years ago, someone requested the feature of <em>rejecting a query before running it</em>. They wanted to analyze the incoming query, and if it was too big or too complicated, reject it.</p>

<p>How could this be implemented? You could provide user access to the AST, but that would leave some difficult processing to user code, for example, merging fragments on interfaces.</p>

<p>So, I added <code>GraphQL::InternalRepresentation</code> as a normalized, pre-processed query structure. Before running a query, the AST was transformed into a tree of <code>irep_node</code>s. Users could analyze that structure and reject queries if desired.</p>

<p>In execution code, why throw away the result of that preprocessing? The runtime also used <code>irep_node</code>s to save re-calculating fragment merging.</p>

<p>In fact, even <em>static validation</em> used the <code>irep_node</code> tree. At some point, rather than re-implement fragment merging, I decided to hook into that rewritten tree to implement <code>FragmentsWillMerge</code>. After all, why throw away that work?</p>

<p>(As it turns out, someone should fire the GraphQL-Ruby maintainer. These layers of code were <em>not</em> well-isolated!!)</p>

<h3>Problem 2.1: Preparing the <code>irep_node</code>s was slow and often a waste</h3>

<p>Since the <code>irep_node</code> tree was built for <em>analysis</em>, it generated branches for <em>every</em> possible combination of interfaces, objects, and unions. This meant that, even for a query returning very simple data, the pre-processing step might be <em>very</em> complex.</p>

<p>To make matters worse, the complexity of this preprocessing would grow as the schema grew. The more implementers an interface has, the longer it takes to calculate the possible branches in a fragment.</p>

<h3>Problem 2.2: Runtime features were implemented during preprocessing</h3>

<p>Not only was the work complex, but it also couldn&rsquo;t be cached. This is because, while building the <code>irep_node</code> tree, <code>@skip</code> and <code>@include</code> would be evaluated with the current query variables. If nodes were skipped, they were left out of the <code>irep_node</code> tree.</p>

<p>This means that, for the <em>same</em> query in your code base, you <em>couldn&rsquo;t</em> reuse the <code>irep_node</code> tree, since the values for those query variables might be different from one execution to the next. Boo, hiss!</p>

<h3>Problem 2.3: A wacky preprocessing step is hard to understand</h3>

<p>I want to empower people to use GraphQL-Ruby in creative ways, but throwing a wacky, custom data structure in the mix doesn&rsquo;t make it easy. I think an easier execution model will encourage people to learn how it works and build cool new stuff!</p>

<h3>Solution: No preprocessing</h3>

<p>The new runtime evaluates the AST directly. Runtime features (<code>@skip</code> and <code>@include</code>, for example) are implemented at, well, <em>runtime</em>!</p>

<h3>Solution: AST Analyzers</h3>

<p>Since you can&rsquo;t use the <code>irep_node</code> tree for analysis anymore, the library includes a new module, <code>GraphQL::Analysis::AST</code>, for preprocessing queries. Shout out to <a href="https://github.com/xuorig">@xuorig</a> for this module!</p>

<h3>Solution: Moving ahead-of-time checks to runtime</h3>

<p>For GitHub, we moved a lot of analyzer behavior to runtime. We did this because it&rsquo;s easier to maintain and requires less GraphQL-specific knowledge to understand and modify. Although the client experience is <em>slightly</em> different, it&rsquo;s still good.</p>

<p>For example, we had an analyzer to check that pagination parameters (eg <code>first</code> and <code>last</code>) were valid. We moved this to runtime, adding it to our connection tooling.</p>

<h3>Solution: <code>GraphQL::Execution::Lookahead</code></h3>

<p><code>irep_node</code>s <em>were</em> useful for looking ahead in a query to see what fields would be selected next. (Honestly, they weren&rsquo;t <em>that good</em>, but they were the only thing we had, beside using the AST directly).</p>

<p>To support that use, we now have <code>extras: [:lookahead]</code> which will inject an instance of <code>GraphQL::Execution::Lookahead</code>, with an API <em>explicitly for</em> checking fields later in the query.</p>

<h2>Other considerations</h2>

<h3>Resolve procs are out</h3>

<p>As part of the change with removing <code>FieldResolutionContext</code>, the new runtime doesn&rsquo;t support proc-style resolvers <code>-&gt;(obj, args, ctx) {...}</code>. Besides <code>ctx</code>, the <code>args</code> objects (<code>GraphQL::Query::Arguments</code>) are not created by the interpreter either. Instead, the interpreter uses plain hashes.</p>

<p>Instead of procs, methods on Object type classes should be used.</p>

<p>This means that proc-based features are also not supported. Field instrumenters and middlewares won&rsquo;t be called; a new feature called field extensions should be used instead.</p>

<h3><code>.to_graphql</code> is <em>almost</em> out</h3>

<p>When the class-based schema API was added to GraphQL-Ruby, there was a little problem. The class-based API was great for developers, but the execution API expected legacy-style objects. The bridge was crossed via a compatibility layer: each type class had a <code>def self.to_graphql</code> method which returned a legacy-style object based on that class. Internally, the class and legacy object were cached together.</p>

<p>The interpreter <em>doesn&rsquo;t</em> use those legacy objects, only classes. So, any type extensions that you&rsquo;ve built will have to be supported on those <em>classes</em>.</p>

<p>The catch is, I&rsquo;m not <em>100% sure</em> that uses of legacy objects have all been migrated. In GitHub, we transitioned by delegating methods from the legacy objects to their source classes, and I haven&rsquo;t removed those delegations yet. So, there might still be uses of legacy objects ðŸ˜….</p>

<p>In a future version, I want to remove the use of those objects <em>completely</em>!</p>

<h1>Conclusion</h1>

<p>I hope this post has clarified some of the goals and approaches toward adding the new runtime. I&rsquo;m already building new features for it, like custom directives and better subscription support. If you have a question or concern, please <a href="https://github.com/rmosolgo/graphql-ruby/issues/new">open an issue</a> to discuss!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Trampolining]]></title>
    <link href="http://rmosolgo.github.io/blog/2018/09/23/trampolining/"/>
    <updated>2018-09-23T21:04:00-04:00</updated>
    <id>http://rmosolgo.github.io/blog/2018/09/23/trampolining</id>
    <content type="html"><![CDATA[<p>As part of my work on <a href="https://github.com/rmosolgo/graphql-ruby/pull/1394">improving GraphQL-Ruby&rsquo;s runtime performance</a>, I&rsquo;ve been reading <a href="http://www.eopl3.com/"><em>Essentials of Programming Languages</em></a>. Here, I try to apply their lesson about &ldquo;trampolining&rdquo;.</p>

<!-- more -->


<p><strong>TL;DR:</strong> I applied a thing I read in a textbook and it:</p>

<ul>
<li>reduced the stack trace size by 80%</li>
<li>reduced the live object count by 15%</li>
<li>kept the same runtime speed</li>
</ul>


<p>You can see the diff and benchmark results here: <a href="https://github.com/rmosolgo/graphql-ruby/compare/1b306fad...eef73b1">https://github.com/rmosolgo/graphql-ruby/compare/1b306fad...eef73b1</a></p>

<h2>The Problem</h2>

<p>It&rsquo;s a bit funny, but it&rsquo;s not <em>totally clear</em> to me what the book is trying to get at here. In the book, they talk about <em>control context</em> or <em>continuations</em> in a way that I would talk about &ldquo;stack frames&rdquo;. I think the problem is this: when you implement a programming language as an interpreter, you end up with recursive method calls, and that recursion builds up a big stack in the host language. This is bad because it hogs memory.</p>

<p>I can definitely <em>imagine</em> that this is a problem in Ruby, although I haven&rsquo;t measured it. GraphQL-Ruby uses recursion to execute GraphQL queries, and I can <em>imagine</em> that those recursive backtrace frames hog memory for a couple reasons:</p>

<ul>
<li>The control frames themselves (managed by YARV or something) take up memory in their own right</li>
<li>The control frames each have a lexical scope (<code>binding</code>), which, since it&rsquo;s still on the stack, can&rsquo;t be GCed. So, Ruby holds on to a lot of objects which <em>could</em> be garbaged collected if the library was written better.</li>
</ul>


<p>Besides that, the long backtrace adds a lot of noise when debugging.</p>

<h2>Trampolining</h2>

<p>In the book, they say, &ldquo;move your recursive calls to tail position, then, assuming your language has tail-call optimization, you won&rsquo;t have this problem.&rdquo; Well, my language <em>doesn&rsquo;t</em> have tail-call optimization, so I <em>do</em> have this problem! (Ok, it&rsquo;s an <a href="https://ruby-doc.org/core-2.4.0/RubyVM/InstructionSequence.html#method-c-compile_option-3D">option</a>.)</p>

<p>Luckily for me, they describe a technique for solving the problem <em>without</em> tail-call optimization. It&rsquo;s called <em>trampolining</em>, and it works roughly like this:</p>

<blockquote><p>When a method <em>would</em> make a recursive call, instead, return a <code>Bounce</code>. Then, the top-level method, which previously received the <code>FinalValue</code> of the interpreter&rsquo;s work, should be extended to accept <em>either</em> a <code>FinalValue</code> or a <code>Bounce</code>. In the case of a <code>FinalValue</code>, it returns the value as previously. In the case of a <code>Bounce</code>, it re-enters the interpreter using the &ldquo;bounced&rdquo; value.</p></blockquote>

<p>Using this technique, a previously-recursive method now <em>returns</em>, giving the caller some information about how to take the next step.</p>

<p>Let&rsquo;s give it a try.</p>

<h2>The Setup</h2>

<p>I want to test impact in two ways: memory consumption and backtrace size. I want to measure these values <em>during</em> GraphQL execution, so what better way to do it but build a GraphQL schema!</p>

<p>You can see the <a href="https://github.com/rmosolgo/graphql-ruby/compare/1b306fad...eef73b1#diff-7a29575d7b0f8a35812f9323ee46febe">whole benchmark</a>, but in short, we&rsquo;ll run a deeply-nested query, and at the deepest point, measure the <em>backtrace size</em> and the number of live objects in the heap:</p>

<pre><code class="ruby">{
  nestedMetric {
    nestedMetric {
      nestedMetric {
        # ... more nesting ...
        nestedMetric {
          backtraceSize
          objectCount
        }
      }
    }
  }
}
</code></pre>

<p>Where the fields are implemented by:</p>

<pre><code class="ruby">def backtrace_size
  caller.size
end

def object_count
  # Make a GC pass
  GC.start
  # Count how many objects are alive in the heap,
  # subtracting the number of live objects before we started
  GC.stat[:heap_live_slots] - self.class.object_count_baseline
end
</code></pre>

<p>We&rsquo;ll use these measurements to assess the impact of the refactor.</p>

<h2>The Pledge: Recursive calls</h2>

<p>To begin with, the interpreter is implemented as a set of recursive methods. The methods do things like:</p>

<ul>
<li>Given an object and a set of selections, resolve the selected fields on that object</li>
<li>Given a value and a type, prepare the value for a GraphQL response according to the type</li>
</ul>


<p>These methods are <em>recursive</em> in the case of fields that return GraphQL objects. The first method resolves a field and calls the second method; then the second method, in order to prepare an object as a GraphQL response, calls back to the first method, to resolve selections on that object. For example, execution might work like this:</p>

<ul>
<li>Resolve selections on the root object

<ul>
<li>One of the selections returned a User

<ul>
<li>Resolve selections on the User

<ul>
<li>One of the selections returns a Repository

<ul>
<li>Resolve selections on the Repository

<ul>
<li>&hellip;</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Do you see how the same procedure is being applied over and over, in a nested way? That&rsquo;s implemented with recursive calls in GraphQL-Ruby.</p>

<p>We can run our test to see how the Ruby execution context looks in this case:</p>

<pre><code class="ruby"># $ ruby test.rb
1b306fad3b6b35dd06248028883cd8a3ec4bdefd
{"backtraceSize"=&gt;282, "objectCount"=&gt;812}
</code></pre>

<p>This is the baseline for backtrace size and object count, which we&rsquo;re using to measure <em>memory overhead</em> in GraphQL execution. (This describes behavior at <a href="https://github.com/rmosolgo/graphql-ruby/commit/2401afc4a19f2e5616e1e155f953ec403bf4896c">this commit</a>.)</p>

<h2>The Turn: Moving Recursive Calls into Tail Position</h2>

<p>As a requirement for the final refactor, we have to do some code reorganization. In the current code, the recursive calls require some setup and teardown around them. For example, we track the GraphQL &ldquo;path&rdquo;, which is the list of fields that describe where we are in the response. Here&rsquo;s a field with its &ldquo;path&rdquo;:</p>

<pre><code class="ruby">{
  a {
    b {
      c # The path of this field ["a", "b", "c"]
    }
  }
}
</code></pre>

<p>In the code, it looks something like this:</p>

<pre><code class="ruby"># Append to the path for the duration of the nested call
@path.push(field_name)
# Continue executing, with the new path in context
execute_recursively(...)
# Remove the entry from `path`, since we're done here
@path.pop
</code></pre>

<p>The problem is, if I want to refactor <code>execute_recursively</code> to become a <code>Bounce</code>, it won&rsquo;t do me any good, because the value of <code>execute_recursively</code> <em>isn&rsquo;t returned</em> from the method. It&rsquo;s not the last call in the method, so its value isn&rsquo;t returned. Instead, the value of <code>@path.pop</code> is returned. (It&rsquo;s not used for anything.)</p>

<p>This is to say: <code>@path.pop</code> is in <em>tail position</em>, the last call in the method. But I want <code>execute_recursively</code> to be in tail position.</p>

<h3>A Hack Won&rsquo;t Work</h3>

<p>The easiest way to &ldquo;fix&rdquo; that would be to refactor the method to return the value of <code>execute_recursively</code>:</p>

<pre><code class="ruby"># Append to the path for the duration of the nested call
@path.push(field_name)
# Continue executing
return_value = execute_recursively(...)
# Remove the entry from `path`, since we're done here
@path.pop
# Manually return the execution value
return_value
</code></pre>

<p>The problem is, when <code>execute_recursively</code> is refactored to be a <code>Bounce</code>:</p>

<pre><code class="ruby"># Append to the path for the duration of the nested call
@path.push(field_name)
# Continue executing
bounce = prepare_bounce(...)
# Remove the entry from `path`, since we're done here
@path.pop
# Manually return the execution value
bounce
</code></pre>

<p>By the time the <code>bounce</code> is actually executed, <code>path</code> <em>won&rsquo;t have</em> the changes I need in it. The value is pushed <em>and popped</em> before the bounce is actually called.</p>

<h3>Pass the Path as Input</h3>

<p>The solution is to remove the need for <code>@path.pop</code>. This can be done by creating a <em>new path</em> and passing it as input.</p>

<pre><code class="ruby"># Create a new path for nested execution
new_path = path + [field_name]
# Pass it as an input
execute_recursively(new_path, ...)
</code></pre>

<p>Now, <code>execute_recursively</code> is in tail position!</p>

<p>(The actual refactor is here: <a href="https://github.com/rmosolgo/graphql-ruby/commit/ef6e94283ecf280b14fe5417a4ee6896a06ebe69">https://github.com/rmosolgo/graphql-ruby/commit/ef6e94283ecf280b14fe5417a4ee6896a06ebe69</a>)</p>

<h2>The Prestige: Make it Bounce</h2>

<p>Now, we want to replace recursive calls with a <em>bounce</em>, where a bounce is an object with enough information to continue execution at a later point in time.</p>

<p>Since my recursive interpreter is implemented with a bunch of stateless methods (they&rsquo;re stateless since the refactor above), I can create a Bounce class that will continue by calling the same method:</p>

<pre><code class="ruby">class Bounce
  # Take the inputs required to call the next method
  def initialize(object, method, *arguments)
    @object = object
    @method = method
    @arguments = arguments
  end

  # Continue by calling the method with the given inputs
  def continue
    @object.send(@method, *@arguments)
  end
end
</code></pre>

<p>Then, I replace the tail-position recursive calls with bounces:</p>

<pre><code class="diff">- execute_recursively(...)
+ Bounce.new(self, :execute_recursively, ...)
</code></pre>

<p>Instead of <em>growing</em> the backtrace by calling another method, we&rsquo;ll be <em>shrinking</em> the backtrace by returning from the current method with a Bounce.</p>

<p>You can see the refactor here: <a href="https://github.com/rmosolgo/graphql-ruby/commit/b8e51573652b736d67235080e8b450d6fc9cc92e">https://github.com/rmosolgo/graphql-ruby/commit/b8e51573652b736d67235080e8b450d6fc9cc92e</a></p>

<h3>How&rsquo;d it work?</h3>

<p>Let&rsquo;s run the test:</p>

<pre><code class="ruby"># $ ruby test.rb
b8e51573652b736d67235080e8b450d6fc9cc92e
{"backtraceSize"=&gt;55, "objectCount"=&gt;686}
</code></pre>

<p>It&rsquo;s a success! The <code>backtraceSize</code> decreased from 282 to 55. The <code>objectCount</code> decreased from <code>812</code> to <code>686</code>.</p>

<h3>Implementation Considerations</h3>

<p><strong>&ldquo;Trampolining&rdquo;</strong> is the process of taking each bounce and continuing it. In my first implementation, <code>def trampoline</code> looked like this:</p>

<pre><code class="ruby"># Follow all the bounces until there aren't any left
def trampoline(bounce)
  case bounce
  when Bounce
    trampoline(bounce.continue)
  when Array
    bounce.each { |b| trampoline(b) }
  else
    # not a bounce, do nothing
  end
end
</code></pre>

<p>My test indicated no improvement in memory overhead, so I frustratedly called it quits. While brushing my teeth before bed, it hit me! I had unwittingly <em>re-introduced</em> recursive method calls. So, I hurried downstairs and reimplemented <code>def trampoline</code> to use a <code>while</code> loop and a buffer of bounces, an approach which didn&rsquo;t grow the Ruby execution context. Then the test result was much better.</p>

<p>Another consideration is the <em>overhead of Bounces</em> themselves. My first implementation creates a bounce before resolving each field. For very large responses, this will add a lot of overhead, especially when the field is a simple leaf value. This should be improved somehow.</p>

<h2>What about Speed?</h2>

<p>It turns out that visitors to the website don&rsquo;t care about backtrace size or Ruby heap size, they just care about waiting for webpages to load. Lucky for me, my benchmark includes some runtime measurements, and the results were basically the same:</p>

<pre><code class="text"># before
Calculating -------------------------------------
                         92.144  (Â±10.9%) i/s -    456.000  in   5.022617s
# after
Calculating -------------------------------------
                        113.529  (Â± 7.9%) i/s -    567.000  in   5.031847s
</code></pre>

<p>The runtime performance was very similar, almost within the margin of error. However, the consideration of Bounce overhead described above could cause <em>worse</em> performance in some cases.</p>

<h2>What&rsquo;s next?</h2>

<p>This code isn&rsquo;t <em>quite</em> ready for GraphQL-Ruby, but I think it&rsquo;s promising for a few reasons:</p>

<ul>
<li>The reduction of memory overhead and backtrace noise could pay off for very large, nested queries</li>
<li>I might be able to leverage bounces to give the caller more control over how GraphQL queries are executed. For example, at GitHub, we use GraphQL queries when rendering HTML pages. With some work, maybe we could alternate between bouncing GraphQL and rendering HTML, so we&rsquo;d get a better progressive rendering experience on the front end.</li>
</ul>


<p>However, one serious issue still needs to be addressed: what about the <code>Bounce</code>&rsquo;s <em>own</em> overhead? Allocating a new object for <em>every field execution</em> is already a performance issue in GraphQL-Ruby, and I&rsquo;m trying hard to remove it. So the implementation will need to be more subtle in that regard.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Trip Report: Balkan Ruby 2018]]></title>
    <link href="http://rmosolgo.github.io/blog/2018/06/14/trip-report-balkan-ruby-2018/"/>
    <updated>2018-06-14T15:02:00-04:00</updated>
    <id>http://rmosolgo.github.io/blog/2018/06/14/trip-report-balkan-ruby-2018</id>
    <content type="html"><![CDATA[<p>This May, I had the opportunity to attend <a href="https://balkanruby.com/">Balkan Ruby</a> and present on my work with <a href="https://github.com/rmosolgo/graphql-ruby">graphql-ruby</a>.</p>

<!-- more -->


<p>Here are a few thoughts about the trip.</p>

<h2>The Conference</h2>

<p>Balkan Ruby was a big hit. Personally, some of my favorites were:</p>

<ul>
<li>Zach Holman&rsquo;s opening talk about datetimes and timezones (which became a <a href="https://zachholman.com/talk/utc-is-enough-for-everyone-right">blog post</a> and inspired a <a href="https://github.com/rmosolgo/graphql-ruby/pull/1566">GraphQL-Ruby ISO8601 scalar type</a>)</li>
<li>Sameer Deshmukh&rsquo;s presentation about various <a href="https://github.com/sciruby">SciRuby</a> projects</li>
<li>Marko BogdanoviÄ‡&rsquo;s talk about <a href="https://rubybench.org/">RubyBench</a>, which was a really cool project and made me want something like it for GraphQL-Ruby.</li>
</ul>


<p>One of my favorite parts of the conference was the code challenges set up by <a href="">Receipt Bank</a>, one of the sponsors.</p>

<p><img src="/images/balkan_ruby_2018/challenge.png" width="500"></p>

<p>Every few hours, a new, wacky challenge would go live. Although I didn&rsquo;t do well on them, I enjoyed working with a few new friends on different solutions, and seeing the creative things that other attendees submitted!</p>

<h2>The City</h2>

<p>Sofia was <strong>great</strong>. A beautiful city with interesting architecture, tons of trees and tasty food.</p>

<p>The Nevski Cathedral was built in the early 1900s to celebrate Russia&rsquo;s liberation of Bulgaria from the Ottomans:</p>

<p><img src="/images/balkan_ruby_2018/nevski.png" width="500"></p>

<p>Inside, a mural of Abraham and Isaac:</p>

<p><img src="/images/balkan_ruby_2018/abraham.png" width="500"></p>

<p>And St. Cyril and St. Methodius, creators of the Cyrillic alphabet, who are quite popular around here:</p>

<p><img src="/images/balkan_ruby_2018/saints.png" width="500"></p>

<p>I really enjoyed the different cathedrals. There&rsquo;s something cool about the different instructive artwork and &ldquo;sacred&rdquo; feeling of a beautiful building with incense burning. I wonder if modern American churches could do more to engage all of our senses.</p>

<p>Also, a bit of Soviet history found in a nearby park:</p>

<p><img src="/images/balkan_ruby_2018/soviet.png" width="500"></p>

<p>And here, some recently excavated Roman ruins, and the one remaining Turkish mosque downtown:</p>

<p><img src="/images/balkan_ruby_2018/ruins.png" width="500"></p>

<p>The mosque was right beside ruins of an old bathhouse. Apparently that&rsquo;s why Sofia was founded here &ndash; there were hot springs on the road between Rome and Constantinople, so the Romans set up camp (and called it Serdica).</p>

<p>And a fairly typical meal during my time there, a <em>shopska</em> salad (veggies with cheese, oil, and vinegar):</p>

<p><img src="/images/balkan_ruby_2018/food.png" width="500"></p>

<p>I can&rsquo;t say enough good things about the local dairy products. The cheese was soft and fresh and the yogurt was tart and refreshing.</p>

<h2>The Organizers</h2>

<p>My favorite part about programming conferences is meeting the smart, caring folks who make them possible, and Balkan Ruby was no exception.</p>

<p>The two main organizers, <a href="https://twitter.com/gsamokovarov">Genadi</a> and <a href="https://twitter.com/vestimir">Vestimir</a> were fantastic hosts (and experienced, since they got their start with Euruko a few years back). Besides that, I really enjoyed meeting the volunteers and learning a bit about life in Sofia.</p>

<p>One thing that stood out to me was the tradition behind the local liquor, rakia. It turns out that many families make it themselves, despite a law against owning stills. I&rsquo;ve been reading that peach wine was the traditional alcoholic drink for the earliest European arrivals to my area, so I decided to give it a shot this summer!</p>

<p>A big bonus was when Vestimir played trail guide for our hike up the nearby mountain, Mt. Vitosha. It turned out to be a gray day, but we had a blast anyways.</p>

<p>Some pictures of the trail:</p>

<p><img src="/images/balkan_ruby_2018/trail1.png" width="500"></p>

<p><img src="/images/balkan_ruby_2018/trail2.png" width="500"></p>

<p><img src="/images/balkan_ruby_2018/trail3.png" width="500"></p>

<p>Beautiful! But you could say were were <em>a bit</em> underdressed XD</p>

<p>At the summit, we were happy to find a lodge where some food was served.</p>

<p><img src="/images/balkan_ruby_2018/hut.png" width="500"></p>

<p>Some traditional bean soup, bread, <a href="https://en.wikipedia.org/wiki/Ljutenica">lyutenitsa</a>, cheese tea, and rakia never tasted so good.</p>

<p><img src="/images/balkan_ruby_2018/snack.png" width="500"></p>

<p>Enjoying a rest:</p>

<p><img src="/images/balkan_ruby_2018/group.png" width="500"></p>

<p>(Left-to-right: Andreas, Nynne, Sameer, Me and Vestimir)</p>

<p>And, pleasantly, we caught a nice view of Sofia on the way back down:</p>

<p><img src="/images/balkan_ruby_2018/overlook.png" width="500"></p>

<p>(You can even see the Nevski cathedral if you look closely!)</p>

<h2>Closing Thoughts</h2>

<p>Balkan Ruby was a big hit on all fronts: great people, great city, great technical content. Especially as a dairy lover, I&rsquo;ll take the next chance I get to go back! And I loved making some new friends, who I hope to see at future Ruby events.</p>
]]></content>
  </entry>
  
</feed>
